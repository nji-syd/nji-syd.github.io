<!DOCTYPE html>
<html lang="en-US">
	<head>
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width,initial-scale=1">

		
		<title>How Dumb is Your Data? &middot; The Future Has Arrived</title>
		

		
			
		

		

		
		

		

		<link rel="stylesheet" href="../../../../font-awesome/css/font-awesome.min.css" type="text/css">
		<link rel="stylesheet" href="../../../../css/poole.css">
		<link rel="stylesheet" href="../../../../css/syntax.css">
		<link rel="stylesheet" href="../../../../css/hyde.css">
		
		
		<link href="" rel="alternate" type="application/rss+xml" title="The Future Has Arrived">
		<link href="../../../../2018/08/13/how-dumb-is-your-data" rel="canonical">
	</head>

	<body class="  h-entry">
		<main class="content container" role="main">
			<article class="post">
				<header>
					<a class="u-url" href="../../../../2018/08/13/how-dumb-is-your-data">
						<h1 class="post-title p-name">How Dumb is Your Data?</h1>
					</a>
					<time class="post-date dt-published" datetime="2018-08-13T00:00:00Z">Monday, 13 August 2018</time>
				</header>
				<main class="post-content e-content">
					<script src="../../../../rmarkdown-libs/kePrint/kePrint.js"></script>
<script src="../../../../rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="../../../../rmarkdown-libs/viz/viz.js"></script>
<link href="../../../../rmarkdown-libs/DiagrammeR-styles/styles.css" rel="stylesheet" />
<script src="../../../../rmarkdown-libs/grViz-binding/grViz.js"></script>


<p><img src="../../../../post/2018-08-13-how-dumb-is-your-data_files/owl-crop-wide.jpg" width="800" /></p>
<p>Recently there seems to be an escalation of hype around AI. One recent article by Nan Li entitled, <a href="https://worldpositive.com/the-new-intelligence-e3e1ff697f11">The New Intelligence</a> starts like this</p>
<blockquote>
<h4 id="modern-ai-and-the-fundamental-undoing-of-the-scientific-method">Modern AI and the fundamental undoing of the scientific method</h4>
<p><em>The days of traditional, human-driven problem solving — developing a hypothesis, uncovering principles, and testing that hypothesis through deduction, logic, and experimentation — may be coming to an end. A confluence of factors (large data sets, step-change infrastructure, algorithms, and computational resources) are moving us toward an entirely new type of discovery, one that sits far beyond the constraints of human-like logic or decision-making: driven solely by AI, rooted in radical empiricism. The implications — from how we celebrate scientific discovery to assigning moral responsibility to those discoveries — are far-reaching.</em></p>
</blockquote>
<p>I share this passage because it embodies some of the popularist trends in thinking about AI, namely:</p>
<ul>
<li>Human driven problem solving is becoming less important.</li>
<li>Machine learning tools can automatically make sense of the data.</li>
<li>That strong AI is on the door step.</li>
</ul>
<p>In <a href="../../../../2018/08/10/human-like-abilities-in-30-lines-of-code/">Part One</a> of this series we saw how a deep learning neural network can take large quantities of unstructured data with little human help and answer useful queries such as <em>which breed of dog is this?</em> And in these contexts, the answers are often better than human level performance. As significant as these breakthroughs are, these problems are typically about correlating unstructured inputs (pixels, text, audio) with associated outputs. There is no reasoning about the world, or making sense of structured data - a task which ultimately falls to us as humans.</p>
<p>The limitations of the data centric approach are discussed by <a href="https://en.wikipedia.org/wiki/Judea_Pearl">Judea Pearl</a> in his latest book <a href="https://www.amazon.com/Book-Why-Science-Cause-Effect/dp/046509760X/">The Book of Why</a>. Pearl, one of the pioneers of Bayesian Networks, points out that much of our knowledge as humans is based on causal understanding rather than mere data or facts. He identifies three levels of causal sophistication, placing modern techniques such as deep learning on the lowest rung (association):</p>
<ol style="list-style-type: decimal">
<li><strong>Association</strong>: The level of seeing and observing. How would seeing X change my belief in Y?</li>
<li><strong>Intervention</strong>: The level of doing and intervening. What would Y be if I do X?</li>
<li><strong>Imagining</strong>: The level of retrospection and understanding. What if X had not occurred? What if I had acted differently?</li>
</ol>
<p>In the words of Pearl:</p>
<blockquote>
<p>Some readers may be surprised to see that I have placed present-day learning machines squarely on rung one of the Ladder of Causation, sharing the wisdom of an owl. We hear almost every day, it seems, about rapid advances in machine learning systems–self-driving cars, speech-recognition systems, and, especially in recent years, deep-learning algorithms (or deep neural networks). How could they still be only at level one?</p>
<p>The successes of deep learning have been truly remarkable and have caught many of us by surprise. Nevertheless, deep learning has succeeded primarily by showing that certain questions or tasks we thought were difficult are in fact not. It has not addressed the truly difficult questions that continue to prevent us from achieving humanlike AI. As a result the public believes that “strong AI”, machines that think like humans, is just around the corner or maybe even here already. In reality nothing could be further from the truth.</p>
</blockquote>
<p>Whether or not you agree with Pearls assessment that, “…tasks we thought were difficult are in fact not”, the causal approach he champions is a profound and recent development in the history of statistics. Historically statistics has been a data centric discipline that emphasised correlation, but avoided any notion of causation.</p>
<p>To appreciate the limitations of the data centric approach, consider a simple example. Table One shows data for a hypothetical observational study which considers the impact of a drug on the risk of heart attack.</p>
<div id="table-one-observational-study-one" class="section level4">
<h4>Table One: Observational Study One</h4>
<table class="table table-hover" style="width: auto !important; ">
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Control Group
</div>
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Treatment Group
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Heart Attack
</th>
<th style="text-align:left;">
No Heart Attack
</th>
<th style="text-align:left;">
Heart Attack
</th>
<th style="text-align:left;">
No Heart Attack
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
Total
</td>
<td style="text-align:left;font-weight: bold;">
13
</td>
<td style="text-align:left;font-weight: bold;">
47
</td>
<td style="text-align:left;font-weight: bold;">
11
</td>
<td style="text-align:left;font-weight: bold;">
49
</td>
</tr>
</tbody>
</table>
<p>We don’t need a deep neural network or machine learning to analyse the data. The proportion of people in the treatment group who suffered a heart attack was 18.3% (11/60) as compared with the proportion who had heart attacks in the control group 21.7% (13/60). So it seems intuitive to conclude that the drug reduces the risk of heart attack.</p>
<p>But what about if you had some more information? Table Two includes gender for the same study.</p>
</div>
<div id="table-two-observational-study-one" class="section level4">
<h4>Table Two: Observational Study One</h4>
<table class="table table-hover" style="width: auto !important; ">
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Control Group
</div>
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Treatment Group
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Heart Attack
</th>
<th style="text-align:left;">
No Heart Attack
</th>
<th style="text-align:left;">
Heart Attack
</th>
<th style="text-align:left;">
No Heart Attack
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;background-color: white;">
Female
</td>
<td style="text-align:left;background-color: white;">
1
</td>
<td style="text-align:left;background-color: white;">
19
</td>
<td style="text-align:left;background-color: white;">
3
</td>
<td style="text-align:left;background-color: white;">
37
</td>
</tr>
<tr>
<td style="text-align:left;background-color: white;">
Male
</td>
<td style="text-align:left;background-color: white;">
12
</td>
<td style="text-align:left;background-color: white;">
28
</td>
<td style="text-align:left;background-color: white;">
8
</td>
<td style="text-align:left;background-color: white;">
12
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Total
</td>
<td style="text-align:left;font-weight: bold;">
13
</td>
<td style="text-align:left;font-weight: bold;">
47
</td>
<td style="text-align:left;font-weight: bold;">
11
</td>
<td style="text-align:left;font-weight: bold;">
49
</td>
</tr>
</tbody>
</table>
<p>Notice the totals are the same, but now we also have the results based on gender.
For women the rate of heart attack was 7.5% (3/40) under treatment vs 5% (1/20) in control and for men 40% (8/20) under treatment vs 30% (12/40) under control. So now it seems the drug increases the risk for women and for men, but overall decreases the risk.</p>
<p>How can that be?</p>
<p>This is the first element of the problem that confronted statistician Edward Simpson in 1951 and became known as <a href="https://en.wikipedia.org/wiki/Simpson%27s_paradox">Simpson’s Paradox</a><sup>1</sup></p>
<p>The first part of the paradox is the reversal of proportions when comparing the data in aggregate to the data stratified on gender. This may seem surprising at first, but if you look at the proportion of men in the treatment group and the control group you can clearly see how this has happened. Men are under represented in the treatment group and over-represented in the control group. They are also at much higher risk of heart attack. This is what has caused the aggregate treatment effect to look encouraging by comparison to the control group.</p>
<p>Viewed in this light it’s clear that in this observational study, gender is a confounding variable. Moreover we can remove the confounding effect by stratifying on gender and normalizing the treatment and control groups based on their size. This practice is know as <a href="https://en.wikipedia.org/wiki/Inverse_probability_weighting">Inverse Probability of Treatment Weighting</a> (IPTW)</p>
</div>
<div id="table-three-observational-study-one-iptw" class="section level4">
<h4>Table Three: Observational Study One (IPTW)</h4>
<table class="table table-hover" style="width: auto !important; ">
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Control Group
</div>
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Treatment Group
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Heart Attack
</th>
<th style="text-align:left;">
No Heart Attack
</th>
<th style="text-align:left;">
Heart Attack
</th>
<th style="text-align:left;">
No Heart Attack
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;background-color: white;">
Female
</td>
<td style="text-align:left;background-color: white;">
1 x 2 = 2
</td>
<td style="text-align:left;background-color: white;">
19 x 2 = 38
</td>
<td style="text-align:left;background-color: white;">
3
</td>
<td style="text-align:left;background-color: white;">
37
</td>
</tr>
<tr>
<td style="text-align:left;background-color: white;">
Male
</td>
<td style="text-align:left;background-color: white;">
12
</td>
<td style="text-align:left;background-color: white;">
28
</td>
<td style="text-align:left;background-color: white;">
8 x 2 = 16
</td>
<td style="text-align:left;background-color: white;">
12 x 2 = 24
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Total
</td>
<td style="text-align:left;font-weight: bold;">
14
</td>
<td style="text-align:left;font-weight: bold;">
66
</td>
<td style="text-align:left;font-weight: bold;">
19
</td>
<td style="text-align:left;font-weight: bold;">
61
</td>
</tr>
</tbody>
</table>
<p>Adjusting for gender the treatment effect is 23.8% (19/80) vs control of 17.5% (14/80), as compared with unadjusted rates of 18.3% and 21.7% respectively. More significantly our conclusion that the drug is good for heart attacks has reversed to the drug being bad for heart attacks.</p>
<p>In <a href="../../../../2018/08/10/human-like-abilities-in-30-lines-of-code/">Part One</a> of this series we saw the magic of deep learning in action. In just 30 lines of code we shoveled in the data and the neural network figured out all the answers, better than most humans could. But operating on the level of association, here the deep neural network can’t help. If we feed it the wrong associations the conclusions will also be wrong.</p>
<p>OK. But what if we just stratify the data before doing machine learning? Let’s consider one final example. The data in table 4 is exactly the same as the previous study, except this time the scenario is different. The drug in question lowers blood pressure. The sub groups are now blood pressure, rather than gender.</p>
</div>
<div id="table-four-observational-study-two" class="section level4">
<h4>Table Four: Observational Study Two</h4>
<table class="table table-hover" style="width: auto !important; ">
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Control Group
</div>
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Treatment Group
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Heart Attack
</th>
<th style="text-align:left;">
No Heart Attack
</th>
<th style="text-align:left;">
Heart Attack
</th>
<th style="text-align:left;">
No Heart Attack
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;background-color: white;">
Low Blood Pressure
</td>
<td style="text-align:left;background-color: white;">
1
</td>
<td style="text-align:left;background-color: white;">
19
</td>
<td style="text-align:left;background-color: white;">
3
</td>
<td style="text-align:left;background-color: white;">
37
</td>
</tr>
<tr>
<td style="text-align:left;background-color: white;">
High Blood Pressure
</td>
<td style="text-align:left;background-color: white;">
12
</td>
<td style="text-align:left;background-color: white;">
28
</td>
<td style="text-align:left;background-color: white;">
8
</td>
<td style="text-align:left;background-color: white;">
12
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Total
</td>
<td style="text-align:left;font-weight: bold;">
13
</td>
<td style="text-align:left;font-weight: bold;">
47
</td>
<td style="text-align:left;font-weight: bold;">
11
</td>
<td style="text-align:left;font-weight: bold;">
49
</td>
</tr>
</tbody>
</table>
<p>In the previous experiment, gender was a confounding variable, but what about blood pressure? Looking at the data in table four, it’s clear that the drug appears to be lowering blood pressure. Two thirds of participants in the treatment group have low blood pressure as compared with 1/3 in the control group. Additionally the rate of heart attack in the low blood pressure group is significantly lower. This appears consistent with an effective drug.</p>
<p>Does it make sense to adjust the data as we did above, and conclude that the drug is bad?</p>
<p>Clearly not. In this case there is no confounding and it doesn’t make sense to adjust for blood pressure. This is the second part of Simpson’s paradox. Same data, different conclusion. The differences between the two scenarios are indicated by causal relationships shown in figures one and two.</p>
</div>
<div id="figure-one-causal-diagram---observational-study-one" class="section level4">
<h4>Figure One: Causal Diagram - Observational Study One</h4>
<div id="htmlwidget-1" style="width:500px;height:400px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"diagram":"\ndigraph {\n\ngraph [layout = dot,rankdir = TB, nodesep = 1, ranksep = 0.5]\n\nnode [shape = circle,\n      style = filled,\n      color = black,\n      fillcolor = \"whitesmoke\",\n      fixedsize = true,\n      width = 0.5,\n      fontname = Helvetica,\n      fontcolor = black,\n      fontsize = 8]\n\nsubgraph {\n  node [label = \"gender\"]\n  gender\n}\n\nsubgraph {\n  rank = same;\n  node [label = \"drug\"] drug;\n  node [label = \"heart\nattack\"] heart_attack\n}\n\nedge [color = orangered]\ngender -> {drug heart_attack}\ndrug -> {heart_attack}\n}\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
<div id="figure-two-causal-diagram---observational-study-two" class="section level4">
<h4>Figure Two: Causal Diagram - Observational Study Two</h4>
<div id="htmlwidget-2" style="width:500px;height:400px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-2">{"x":{"diagram":"\ndigraph {\n\ngraph [pad=\"0.05\", layout = dot,rankdir = TB, nodesep = \"1\", ranksep = \"0.5\"]\n\nnode [shape = circle,\n      style = filled,\n      color = black,\n      fillcolor = \"whitesmoke\",\n      fixedsize = true,\n      width = 0.5,\n      fontname = Helvetica,\n      fontcolor = black,\n      fontsize = 8]\n\nsubgraph {\n  node [label = \"blood\npressure\"]\n  blood_pressure\n}\n\nsubgraph {\n  rank = same;\n  node [label = \"drug\"] drug;\n  node [label = \"heart\nattack\"] heart_attack\n}\n\nedge [color = orangered]\nblood_pressure -> {heart_attack}\ndrug -> {blood_pressure heart_attack}\n}\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
<p>In Figure One Gender is a confounder because it affects both the outcome (heart attack) as well as the likelihood of taking the drug. In Figure Two blood pressure is a mediator and is likely the key mechanism driving the outcome. Adjusting for blood pressure would completely block this effect.</p>
<p>These examples show that given the same data, the conclusions can be different depending on the causal process. Which brings us to this. What matters is not the data, but the data generating process. Understanding the latter allows us to interpret the former. Radical Empiricism has had some spectacular successes. But always rely on it at your peril!</p>
</div>
<div id="references" class="section level3">
<h3>References</h3>
<p><sup>1</sup> Simpson’s original paper <em>The Interpretation of Interaction in Contingency Tables</em> published in the Journal of the Royal Statistical Society presents examples using cards and mortality rates but is somewhat esoteric. Peal’s examples from The Book of Why are more enlightening, and have been used here instead of Simpson’s.</p>
</div>

				</main>
				<footer class="footer">
					
					
				</footer>
			</article>
			<div id="disqus_thread"></div>
<script type="text/javascript">

(function() {
    
    
    if (window.location.hostname == "localhost")
        return;

    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    var disqus_shortname = 'njisyd';
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
		</main>
				<aside class="sidebar">
			<div class="container sidebar-sticky">
				<header class="sidebar-about h-card vcard p-author">
					
					<a class="u-url u-uid" rel="me" href="../../../../">
						<img class="u-photo" src="../../../../author.jpg" width=128 height=128 />
					</a>
					

					
					<span class="site-title u-name fn">
					  <a class="u-url u-uid" rel="me" href="../../../../">The Future Has Arrived</a>
				  </span>
					

					<p class="lead p-note">
						 data science, behavioural finance and the rise of machines 
					</p>

					<nav>
						<ul class="sidebar-nav">
							
							<li><a href="../../../../post/"> Posts </a></li>
							
						</ul>
					</nav>

					
						<aside class="contact">
						  
							  <h3 class="contact-head">Contact Me</h3>
						  
							<ul class="contact-list">
								
								<li>
									
									  
		  						    <i class='fa fa-github fa-fw'></i>
		  						  
		  							<a href="https://github.com/nji-syd" class="u-url url" rel="me">
		  							  GitHub
		  							</a>
								
								</li>
								
								<li>
									
									  
		  						    <i class='fa fa-linkedin fa-fw'></i>
		  						  
		  							<a href="https://linkedin.com/in/nickirelandau" class="u-url url" rel="me">
		  							  LinkedIn
		  							</a>
								
								</li>
								
							</ul>
						</aside>
					
				</header>

				<footer>&copy; 2018. All rights reserved. </footer>
			</div>
		</aside>

		  <footer>
  
  
 
  
<script src="../../../../js/math-code.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


  
  </footer>
  </body>
</html>

	</body>
</html>
